dataset:
  data_dir: '/data/pgsal/ldc_new3'
  data_pkl: '/data/pgsal/ldc_new3/patches_dataset.pkl'
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  input_size: [25, 25, 25]  # 3D input size (D, H, W)
  input_size_2d: 256  # 2D input size (square images)
  patch_size: [64, 64]  # Size of patches for 2D data
  patch_size_3d: [50, 50, 50]  # Size of patches for 3D data
  use_single_file: false  # Set to true to train on a single .npy file
  data_file: null  # Path to single .npy file if use_single_file is true
  test_mode: false  # Can be set at top level or here for backward compatibility
  n_test_samples: 20  # Can be set at top level or here for backward compatibility

# Settings for initial data preparation (before training)
preprocessing:
  normalize: true
  normalize_method: "clinical_then_dl"  # Two-stage normalization approach
  clinical_norm_method: "95percentile"  # First normalize to 95th percentile (clinically meaningful)
  dl_norm_method: "minmax"  # Then normalize for neural network training (0-1 range)
  percentile_norm: 95  # Percentile for normalization (0-100)
  voxel_spacing: [0.5, 0.5, 0.5]  # Physical spacing in mm - CHANGED TO 0.5mm to match pre-trained encoder
  resize_to: [64, 64, 64]  # Target size for resampling
  unit_type: "voxels"  # "voxels" or "mm" - how size values are interpreted
  extract_slices: false  # Whether to extract 2D slices from 3D volumes
  slice_extraction: "informative"  # "all", "center", or "informative"
  non_zero_threshold: 0.05  # For informative slice extraction
  num_workers: 8  # Number of parallel workers
  batch_size: 1  # Batch size for saving
  use_tanh_output: true  # Keep this here for compatibility
  test_mode: false  # Duplicate of dataset.test_mode for compatibility
  n_test_samples: 20  # Duplicate of dataset.n_test_samples for compatibility
  file_format: "nrrd"  # Options: "nifti" or "nrrd"
  nifti_extension: ".nii.gz"  # Used when file_format is "nifti"
  nrrd_extension: ".nrrd"     # Used when file_format is "nrrd"
  # NEW: Interpolation settings for different data types
  ct_interpolation: "linear"         # Linear interpolation for CT (smooth anatomy)
  dose_interpolation: "nearest"      # Nearest neighbor for dose (preserve values)

# Settings for transforms during training (conceptually separate but not used by preprocessing script)
transforms:
  augment: true  # Whether to apply data augmentation during training
  rotate: true  # Random rotation
  flip: true  # Random flipping
  adjust_brightness: true  # Random brightness adjustment
  random_crop: false  # Random cropping during training
  random_noise: false  # Add random noise during training

patch_extraction:
  enable: true  # Set to true to extract patches
  patch_dimension: "3D"  # "2D" or "3D" - dimensionality of patches to extract
  patch_size_voxels: [50, 50, 50]
  patch_unit_type: "voxels"  # CORRECTED: Now using voxels, not mm
  threshold: 0.01  # Standard deviation threshold for informative patches
  max_patches_per_slice: 100  # Maximum number of patches to extract per slice
  max_patches_per_volume: 500  # Maximum number of patches to extract per volume
  random_state: 42  # Random seed for patch extraction
  min_lung_percentage: 0.70  # UPDATED: Minimum 70% lung coverage (from cOOpD paper)
  min_dose_percentage: 0.01  # Minimum percentage of non-zero dose voxels required in a patch
  # NEW: Settings for spatial correspondence
  extract_matched_pairs: true   # Extract CT-dose pairs from same spatial locations
  overlap_percentage: 50        # Patch overlap percentage (50% = 50% overlap like cOOpD)

model:
  type: 'vae'  # Options: 'vae', 'resnet_ae', 'unet_ae', 'conv_autoencoder', 'mlp_autoencoder', 'unet'
  is_2d: false  # Set to true for 2D models
  latent_dim: 128
  in_channels: 1
  base_filters: 32
  bottleneck_filters: 256
  dropout_rate: 0.3  # Dropout rate for regularization

hyperparameters:
  learning_rate: 0.0001
  batch_size: 8
  epochs: 100
  early_stopping_patience: 10
  weight_decay: 0.0001
  beta: 1.0  # KL divergence weight for VAE

training:
  optimizer: 'adam'  # Options: 'adam', 'sgd', 'rmsprop'
  scheduler: 'reduce_on_plateau'  # Options: 'reduce_on_plateau', 'cosine_annealing', 'none'
  loss: 'mse'  # Options: 'mse', 'bce', 'combined'
  gpu_id: 0
  seed: 42
  grad_clip: 0.1  # Gradient clipping threshold
  non_zero_loss: false  # Whether to calculate loss only on non-zero regions
  accumulation_steps: 1  # Gradient accumulation steps

# Clinical metrics settings
clinical_metrics:
  use_pymedphys_gamma: true  # true to use PyMedPhys, false to use custom implementation
  gamma_dose_threshold: 3.0  # Dose difference criterion (%)
  gamma_distance_threshold: 3.0  # Distance-to-agreement (mm)
  dose_threshold_cutoff: 10  # Lower dose cutoff (% of max dose)
  calculate_dvh: true
  dvh_num_bins: 1000
  spacing: [0.5, 0.5, 0.5]  # UPDATED: Voxel spacing in mm to match preprocessing

# Loss function configuration
loss_function:
  type: "combined"  # Options: "mse", "gamma", "dvh", "combined", "clinical"
  weights:
    mse: 1.0
    gamma: 0.1  # Weight for gamma pass rate loss (1 - pass_rate)
    dvh: 0.1    # Weight for DVH difference loss
    d95: 0.05   # Weight for D95 difference
    d50: 0.05   # Weight for D50 difference
    d2: 0.05    # Weight for D2 difference
  gamma_calculation_frequency: 10  # Calculate gamma every N batches (expensive operation)

# Logging configuration
logging:
  log_high_dose_slice: true
  log_frequency: 1  # Log high dose slice every N epochs
  log_reconstructions: true
  reconstruction_frequency: 10  # Log full reconstructions every N epochs
  num_samples_to_log: 4
  visualization_interval: 10  # Interval for logging image visualizations
  random_patches_per_lobe: 5  # REDUCED: Number of random patches to visualize per lung lobe (reduced due to higher resolution)

wandb:
  use_wandb: true
  project_name: 'dose_distribution_autoencoder_05mm'  # UPDATED: Project name to reflect resolution
  entity: 'pgsalome'
  name: 'doseae_05mm_nearest'  # UPDATED: Run name to reflect changes

optuna:
  use_optuna: false
  n_trials: 50
  timeout: 86400  # 24 hours
  direction: 'minimize'  # 'minimize' or 'maximize'
  sampler: 'tpe'  # Options: 'tpe', 'random', 'grid'
  pruner: 'median'  # Options: 'median', 'none'

output:
  model_dir: '/data/pgsal/ldc_doseae'
  log_dir: '/data/pgsal/ldc_doseae/logs'  # UPDATED: Directory name
  results_dir: '/data/pgsal/ldc_doseae'    # UPDATED: Directory name

# NEW: Settings for compatibility with pre-trained encoders
pretrained_encoder:
  use_pretrained_ct_encoder: false  # Set to true when using pre-trained CT encoder
  ct_encoder_path: null             # Path to pre-trained CT encoder weights
  freeze_ct_encoder: true           # Whether to freeze CT encoder during training
  expected_input_spacing: [0.5, 0.5, 0.5]  # Expected input spacing for pre-trained encoder

